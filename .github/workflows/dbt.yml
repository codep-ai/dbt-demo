# .github/workflows/dbt.yml
name: dbt Workflow
on:
  workflow_call:
    inputs:
      account_id:
        required: true
        type: string
      stage:
        required: true
        type: string
      env:
        required: true
        type: string
      env_name:
        required: true
        type: string
      bucket_name:
        required: true
        type: string
      dbt_bucket:
        required: true
        type: string
      redshift_database:
        required: true
        type: string
      tf_var_role_name:
        required: true
        type: string
      github_runner:
        required: true
        type: string
      pr_number:
        type: string
      slim_ci:
        type: string
    secrets:
      AWS_ACCESS_KEY_ID:
        required: true
      AWS_SECRET_ACCESS_KEY:
        required: true
      TEAM_PAT:
        required: true
      redshift_host:
        required: true
      redshift_username:
        required: true
      redshift_password:
        required: true

jobs:
  data-check:
    if: ${{ inputs.stage != 'ci' }}
    name: Data Check
    runs-on: ${{ fromJSON(inputs.github_runner) }}
    environment: ${{ inputs.env }}
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v3
      - run: echo "/home/ubuntu/.local/bin" >> $GITHUB_PATH
      - run: echo "/usr/local/bin" >> $GITHUB_PATH
      - run: sudo ACCEPT_EULA=Y apt-get install -y msodbcsql18 mssql-tools18 openssl
      - name: Fix OpenSSL for GBST Database
        run: sudo sed -i 's/DEFAULT:@SECLEVEL=2/DEFAULT:@SECLEVEL=0/g' /etc/ssl/openssl.cnf      
      - run: pip install pyodbc boto3 redshift-connector pandas
      - uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ap-southeast-2
          role-to-assume: arn:aws:iam::${{ env.TF_VAR_account_id }}:role/${{ env.TF_VAR_role_name }}
          role-duration-seconds: 7200
      - name: Freshness
        run: python3 data_freshness.py

  dbt:
    name: DBT
    runs-on: ${{ fromJSON(inputs.github_runner) }}
    environment: ${{ inputs.env }}
    timeout-minutes: 230
    steps:
      - uses: actions/checkout@v3
      - run: echo "/home/ubuntu/.local/bin" >> $GITHUB_PATH
      - run: echo "/usr/local/bin" >> $GITHUB_PATH
      - run: pip install -r requirements.txt
        working-directory: dbt
      - run: pip install psycopg2 pyyaml psycopg2-binary
      - uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ap-southeast-2
          role-to-assume: arn:aws:iam::${{ env.TF_VAR_account_id }}:role/${{ env.TF_VAR_role_name }}
          role-duration-seconds: 7200
      - name: Resume Redshift Cluster if Stopped
        run: aws redshift resume-cluster --cluster-identifier ${{ inputs.env_name }}-cmc || true
      - run: aws s3 cp ${{ inputs.dbt_bucket }}target/manifest.json .
        working-directory: dbt
      - name: Check Source Files are Updated
        run: python3 update_sources.py || true
      - run: cat source_awcdata.new.yml || true
      - run: cat source_biref.new.yml || true
      - run: cat source_cmcdata_archive.new.yml || true
      - run: cat source_fact.new.yml || true
      - run: cat source_frontoffice.new.yml || true
      - run: cat source_pa_dca.new.yml || true
      - run: cat source_pa_dcah.new.yml || true
      - run: cat source_jpm.new.yml || true
      - if: ${{ inputs.stage != 'ci' }}
        run: python3 save_delta.py
      - run: dbt deps --profiles-dir . --target ${{ inputs.stage }}
        working-directory: dbt
      - name: Check Source Freshness
        run: dbt source freshness --profiles-dir . --target ${{ inputs.stage }}
        if: ${{ inputs.env == 'prod' }}
        working-directory: dbt
      - run: dbt run-operation stage_external_sources --profiles-dir . --target ${{ inputs.stage }}
        working-directory: dbt
      - name: DBT Slim CI Build
        if: ${{ inputs.slim_ci == 'true' || inputs.stage == 'ci' }}
        run: dbt build --profiles-dir . --target ${{ inputs.stage }} --select "@state:modified" --defer --state .
        working-directory: dbt
      - name: DBT Full CI Build
        if: ${{ inputs.slim_ci != 'true' && inputs.stage != 'ci' }}
        run: dbt build --profiles-dir . --target ${{ inputs.stage }}
        working-directory: dbt
      - run: dbt docs generate --profiles-dir . --target ${{ inputs.stage }}
        if: ${{ inputs.stage == 'prod' }}
        working-directory: dbt
      - run: rm dbt_packages/dbt_ml_preprocessing/integration_tests/dbt_packages/dbt_ml_preprocessing
        working-directory: dbt
      - run: aws s3 sync . ${{ inputs.dbt_bucket }} --size-only --delete --exclude 'codeartifact.txt' --exclude 'static/*'
        working-directory: dbt
      - name: Publish Docs ðŸš€
        if: ${{ inputs.stage == 'prod' }}
        uses: JamesIves/github-pages-deploy-action@v4.4.3
        with:
          branch: gh-pages
          folder: dbt/targetÃŸÃŸ